Transformer는 시퀀스 데이터를 목적에 맞는 다른 시퀀스 데이터로 변형시키는 모델입니다. 

주로 번역기에 많이 쓰이며, 번역기로서 구현하면 어떤 언어의 문장을 넣으면, 다른 언어로 번역된 문장이 출력됩니다.

큰 구조를 보면 인코더, 디코더 구조를 가지고 있습니다.

정확히는 인코더 레이어가 쌓여있는 인코더 블럭, 인코더와 같은 개수의 디코더 레이어가 쌓여있는 디코더 블록으로 이루어져 있스빈다.

인코더는 소스 시퀀스 정보를 압축해서 디코더로 보내주고, 디코더는 이 정보를 받아서 타깃 시퀀스를 생성합니다. 


여기서 디코더 블럭을 보면 알겠지만 디코더는 한번에 모든 시퀀스를 출력하는 것이 아니라, RNN 구조와 비슷하게, 시퀀스가 입력되면, 시작 토큰에서 마지막 토큰이 나올 때까지 토큰마다 반복해서 다음 나올 토큰을 예측하는 연산을 진행합니다. 

​

인코더나 디코더의 블록에 입력 값이 들어갈 때는 토큰의 특징을 다루기 쉬운 벡터의 형태로 바꾸는 임베딩 과정을 거칩니다. 

또한, 모델이 각 토큰들의 위치정보를 알 수 있게 Positional Encoding과정으로 해당 임베딩 벡터 값을 조정하여 입력합니다.

​

이 과정을 통해서 순서 정보가 보존되어서 같은 토큰들로 구성된 시퀀스여도 그 위치에 따라서 다른 입력으로 인식하게 됩니다.


인코더 블럭을 살펴보면 다음과 같은 구조를 띄고 있습니다.


간략하게 전체를 훑어보는 것이니까 너무 깊게 들어가지 않고 각각을 설명해보겠습니다.

먼저 멀티-헤드 셀프 어텐션은 미리 설정해둔 횟수(multi-head)만큼 self-attention을 반복해서 수행하겠다는 겁니다.

셀프 어텐션은 아주 간단하게 말로써 설명하자면, 지금 들어온 시퀀스 데이터의 각 토큰 들과 현재 바라보고 있는 토큰의 유사도를 측정하여 해당 토큰의 벡터에 가중치로 반영합니다. 

셀프 어텐션의 효과는 다음과 같습니다.


(구글 AI 블로그 포스트)

지금 it을 보고 있을 때, 셀프 어텐션을 통해 기존의 문장에서 it이 지칭하는 것이 어떤 것에 가장 가까운지 알 수 있습니다.

​

그리고 나서 add&norm 과정을 거치고, 피드 포워드 신경망을 거칩니다. 

이 피드 포워드 신경망을 통해 훈련시 사용했던 시퀀스 데이터들에 없는 토큰에 대해서 예측을 하더라도 유사한 토큰이 사용되었던 시퀀스를 참고해서 더 정확한 예측을 할 수 있게 합니다. 

​

add&norm과정은 잔차 연결(Residual connection)과 정규화 과정을 말하는데, 모델이 더 정확한 학습을 하도록 도와줍니다. 

이 과정을 저렇게 사이사이 진행하게 됩니다.

​

이제는 디코더입니다.


Current Token은 현재까지 추측한 토큰들입니다. 그리고 그 다음 토큰을 예측하면 current tokens 뒤에 해당 토큰이 추가됩니다.

그런데 토큰이 많이 추가되었을 때, Current Token에서 앞의 토큰이 뒤의 토큰에 대한 위치 정보를 가지고 있게 됩니다. 

즉, 미래 시점까지 이미 알게 된다는 것입니다. 이는 마스크를 씌워서 안보이게 합니다.

​

그리고 나서는 Multi-head Attention을 진행합니다. 

인코더와 다르게 Self Attention이 아닌데, 이때에는 자신의 입력 시퀀스(Current Tokens)에 대해서 지금 보고있는 토큰의 유사도를 계산하는 것이 아니라, 인코더가 결과로 내준 압축 벡터에서 현재 토큰의 유사도를 계산하기 때문입니다. 

​

그 뒤로는 인코더와 동일하게 FFNN을 거칩니다.

​

이렇게 간단하게 트랜스포머를 살펴봤습니다. 
